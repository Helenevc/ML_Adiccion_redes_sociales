# %%
import numpy as np
import pandas as pd

from sklearn.model_selection import train_test_split
from sklearn.preprocessing import StandardScaler
from sklearn import metrics
from sklearn.ensemble import RandomForestClassifier
from sklearn.model_selection import cross_val_score
import matplotlib.pyplot as plt
import seaborn as sns
from sklearn.feature_selection import SelectKBest, f_classif
from sklearn.feature_selection import RFE
from sklearn.decomposition import PCA
from imblearn.over_sampling import SMOTE


from sklearn.linear_model import LogisticRegression
from sklearn.neighbors import KNeighborsClassifier
from sklearn.pipeline import make_pipeline
from sklearn.tree import DecisionTreeClassifier
from sklearn.ensemble import GradientBoostingClassifier
from xgboost import XGBClassifier
from lightgbm import LGBMClassifier
from catboost import CatBoostClassifier
from sklearn.model_selection import GridSearchCV
from sklearn.metrics import confusion_matrix
import scipy.stats as ss
from itertools import combinations

import sys
sys.path.append("./src/utils")
import bootcampviztools as bt
import toolbox as tl

# %%
import os
print(os.listdir("./src/utils"))

# %% [markdown]
# **1. Visualizacion general de mis datos**
# 
# Nos encontramos con un Dataset aparentemente limpio, detectamos una columna ID, hacemos una copia de seguridad y quitamos esta columna que no nos sera util. Nos encontramos con un problema supervisado de clasificacion multiclases

# %%
student = pd.read_csv("./src/data_sample/Students_Social_Media_Addiction.csv", sep = ",")
student.head()

# %%
student.info()

# %%
df= student.copy()

# %%
df.drop("Student_ID", axis = 1, inplace = True)

# %% [markdown]
# **2. Separamos nuestro dataset, e identificamos el target:**

# %%
train_set, test_set = train_test_split(df, test_size= 0.2, random_state= 42)
target = "Addicted_Score"

# %%
train_set.columns

# %% [markdown]
# **3. Miremos el target:**
# 
# Nos encontramos frente a un problema de clasificacion multiclase, no balanceado. 

# %%
df[target].value_counts(normalize=True)

# %%
sns.countplot(x= df[target], data = df, hue = target)

# %% [markdown]
# **4. Realizamos un MINI EDA para conocer mejor nuestros datos**
# 
#     - comprension de las variables
#     - analisis univariante
#     - analisis bivariantes

# %%
tl.descripcion(df)

# %%
tl.tipificacion_variables(df,10,30)

# %%
for col in df: 
    print(f"for, {df[col].value_counts(normalize=True)}")
    print("*****************************")

# %%
df["Country"].unique()

# %% [markdown]
# | Columna/Variable | Descripción                                | Tipo de Categoria | Priorizacion | 
# | ---------------- | ------------------------------------------ |--------------------|-------------------------------|
# | Age              | Edad del estudiante                        | Numerica discreta| Baja| 
# | Gender           | Genero del estudiante                     | Binaria| Media|
# | Academic_Level   | Nivel academico (3 tipologias)            | Categorica | Alta| 
# | Country          | Pays del estudiante                       |Categorica |Alta|
# | Avg_Daily_Usage_Hours| Horas de uso de redes sociales al dia |Numerica continua| Alta|
# | Most_Used_Platform   | Plataformas de coneccion              | Categorica | Media|
# | Affects_Academic_Performance  | Si afecta resultados academicos | Binaria | Alta|
# | Sleep_Hours_Per_Night| Horas de sueño                        | Numerica continua | Alta|
# | Mental_Health_Score  | Evaluacion de 0 a 10                  | Categorica |Alta|
# | Relationship_Status  | estado actual de relaciones (3 tipologias) |Categorica | Media |
# | Conflicts_Over_Social_Media   | numero de conflicto con familiares sobre el uso de redes sociales |Categorica |Alta|
# | Addicted_Score       | Clasificacion evaluacion adiccion de 0 a 10 |Categorica | Target|
# 

# %%
features_num = ["Avg_Daily_Usage_Hours",  "Sleep_Hours_Per_Night"]
features_cat = ["Country","Age", "Gender","Most_Used_Platform", "Academic_Level", "Affects_Academic_Performance", "Mental_Health_Score", "Relationship_Status", "Conflicts_Over_Social_Media"]

# %%
train_set[features_cat].mode().T

# %%
bt.pinta_distribucion_categoricas(train_set, features_cat, relativa=False, mostrar_valores=False)

# %%
train_set.hist(figsize=(10,8));
# cuidado algunas engañan porque no son numericas. Son categoricas! 

# %%
train_set.describe()

# %%
for columna in features_num:
    fig, axes = plt.subplots (1,2, figsize=(8,8) )
    plt.suptitle(columna)
    sns.boxplot(x= columna, data = student, ax=axes[0])
    sns.histplot( data = student,x=columna, kde=True,  bins= "auto", ax=axes[1]);

# %%
# BIVARIANTES
features_important_cat= []
less_important_features= []
bt.plot_categorical_relationship_fin(train_set, "Conflicts_Over_Social_Media",target, show_values= True, relative_freq= True)
features_important_cat.append("Conflicts_Over_Social_Media") # relevante

# %%
bt.plot_categorical_relationship_fin(train_set, "Age",target, show_values= True, relative_freq= True)
less_important_features.append("Age")
# AGE no me parece tener una clara dependencia visualmente, no la guardamos


# %%
bt.plot_categorical_relationship_fin(train_set, "Mental_Health_Score",target, show_values= True, relative_freq= True)
features_important_cat.append("Mental_Health_Score") # relevante

# %%
bt.plot_categorical_relationship_fin(train_set, "Most_Used_Platform",target, show_values= True, relative_freq= True)
features_important_cat.append("Most_Used_Platform")#medio relevante si

# %%
bt.plot_categorical_relationship_fin(train_set, "Gender",target, show_values= True, relative_freq= True)
features_important_cat.append("Gender") #medio relevante si

# %%
bt.plot_categorical_relationship_fin(train_set, "Academic_Level",target, show_values= True, relative_freq= True)
features_important_cat.append("Academic_Level") # relevante

# %%
bt.plot_categorical_relationship_fin(train_set, "Affects_Academic_Performance",target, show_values= True, relative_freq= True)
features_important_cat.append("Affects_Academic_Performance") # relevante

# %%
bt.plot_categorical_relationship_fin(train_set, "Relationship_Status",target, show_values= True, relative_freq= True)
features_important_cat.append("Relationship_Status") # medio relevante si



# %%
# Calculo de correlacion entre variantes categoricas .  CRAMERS
def cramers_v(x, y):
    # Contingency table
    confusion = pd.crosstab(x, y)
    chi2 = ss.chi2_contingency(confusion, correction=False)[0]
    n = confusion.sum().sum()
    k = min(confusion.shape)
    return np.sqrt(chi2 / (n * (k - 1)))

# Uso
cramers_v(train_set["Most_Used_Platform"], train_set["Age"])

results = []

for feat1, feat2 in combinations(features_cat, 2):
    v = cramers_v(train_set[feat1], train_set[feat2])
    results.append({
        'Fear1': feat1,
        'Feat2': feat2,
        'CramersV': v
    })

df_cramers = pd.DataFrame(results).sort_values('CramersV', ascending=False)
df_cramers

# %%
corr = train_set[features_num+[target]].corr(numeric_only= True)
np.abs(corr[target].sort_values(ascending = False))
# cuidado aqui las categoricas!!! engaña! 

# %%
#correlation map - cuidado a las falsas numericas que en realidad son categoricas, de las numericas, eligimos solo 1, la mas correlada con target, o sea "Avg_Daily_usage_Hours"
plt.figure(figsize=(4, 4))
sns.heatmap(train_set[features_num+[target]].corr(numeric_only=True), annot=True, linewidths=.5);

# %%
less_important_features.append("Sleep_Hours_Per_Night")

# %%
features_important_num= ["Avg_Daily_usage_Hours"]

# %%
features_important_cat

# %%
sns.pairplot(train_set, hue = target);

# %%
bt.bubble_plot(train_set, "Conflicts_Over_Social_Media", "Sleep_Hours_Per_Night","Addicted_Score",scale = 1 )

# %%
def plot_histo_den(df, columns):
    num_cols = len(columns)
    num_rows = num_cols // 2 + num_cols % 2
    fig, axes = plt.subplots(num_rows, 2, figsize=(12, 6 * num_rows))
    axes = axes.flatten()

    for i, column in enumerate(columns):
        if df[column].dtype in ['int64', 'float64']:
            sns.histplot(df[column], kde=True, ax=axes[i])
            axes[i].set_title(f'Histograma y KDE de {column}')

    # Ocultar ejes vacíos
    for j in range(i + 1, num_rows * 2):
        axes[j].axis('off')

    plt.tight_layout()
    plt.show()

plot_histo_den(train_set,features_num)

# %%
bt.plot_grouped_histograms(student,cat_col= target, num_col="Avg_Daily_Usage_Hours", group_size=8)

# %%
bt.plot_grouped_histograms(student,cat_col= target, num_col="Sleep_Hours_Per_Night", group_size=8)

# %%
features_num

# %%
#correlacion de numericas Exam_Score y Hours Sudied - scatter plot

plt.figure(figsize=(6, 4))
sns.scatterplot(data=train_set, x="Avg_Daily_Usage_Hours", y=target, s=50)
plt.title('Diagrama de Dispersión')
plt.xlabel("Avg_Daily_Usage_Hours")
plt.ylabel("Target")
plt.grid(True)
plt.show()
#plt.savefig("./Imagenes/scatterplot.png")



# %%
plt.figure(figsize=(6, 4))
sns.scatterplot(data=train_set, x="Sleep_Hours_Per_Night", y= target, s=50)
plt.title('Diagrama de Dispersión')
plt.xlabel("Sleep_Hours_Per_Night")
plt.ylabel("Target")
plt.grid(True)
plt.show()

# %%
# TRANSFORMACIONES - importante, tenemos en cuenta posibles outliers a futuro 
# COUNTRY 

country_to_continent = {
    #Asia
    'Afghanistan': 'Asia', 'Armenia': 'Asia', 'Azerbaijan': 'Asia', 'Bahrain': 'Asia',
    'Bangladesh': 'Asia', 'Bhutan': 'Asia', 'Cyprus': 'Asia', 'Georgia': 'Asia',
    'India': 'Asia', 'Indonesia': 'Asia', 'Iraq': 'Asia', 'Israel': 'Asia',
    'Japan': 'Asia', 'Jordan': 'Asia', 'Kazakhstan': 'Asia', 'Kuwait': 'Asia',
    'Kyrgyzstan': 'Asia', 'Lebanon': 'Asia', 'Malaysia': 'Asia', 'Maldives': 'Asia',
    'Nepal': 'Asia', 'Oman': 'Asia', 'Pakistan': 'Asia', 'Philippines': 'Asia',
    'Qatar': 'Asia', 'Singapore': 'Asia', 'South Korea': 'Asia', 'Sri Lanka': 'Asia',
    'Syria': 'Asia', 'Taiwan': 'Asia', 'Tajikistan': 'Asia', 'Thailand': 'Asia',
    'Turkey': 'Asia', 'UAE': 'Asia', 'Uzbekistan': 'Asia', 'Vietnam': 'Asia',
    'Yemen': 'Asia',
    # Africa
    'Egypt': 'Africa', 'Ghana': 'Africa', 'Kenya': 'Africa',
    'Morocco': 'Africa', 'Nigeria': 'Africa', 'South Africa': 'Africa', 'Argelia': 'Africa', 'Angola': 'Africa','Benin': 'Africa', 'Botswana': 'Africa','Burkina Faso': 'Africa','Burundi': 'Africa', 'Cape Verde': 'Africa', 'Cameroon': 'Africa', 'Chad': 'Africa',
    'Comoros': 'Africa','Republic of the Congo': 'Africa',
    # North America
    'Bahamas':'North America', 'Canada': 'North America', 'Costa Rica': 'North America','Jamaica': 'North America', 'Mexico': 'North America', 'Panama': 'North America',
    'Trinidad': 'North America', 'USA': 'North America',
    # South America
    'Argentina': 'South America', 'Bolivia': 'South America', 'Brazil': 'South America',
    'Chile': 'South America', 'Colombia': 'South America', 'Ecuador': 'South America',
    'Paraguay': 'South America', 'Peru': 'South America', 'Uruguay': 'South America',
    'Venezuela': 'South America',
    # Europe
    'Albania': 'Europe', 'Andorra': 'Europe', 'Austria': 'Europe', 'Belarus': 'Europe',
    'Belgium': 'Europe', 'Bosnia': 'Europe', 'Bulgaria': 'Europe', 'Croatia': 'Europe',
    'Czech Republic': 'Europe', 'Denmark': 'Europe', 'Estonia': 'Europe', 'Finland': 'Europe',
    'France': 'Europe', 'Germany': 'Europe', 'Greece': 'Europe', 'Hungary': 'Europe',
    'Iceland': 'Europe', 'Ireland': 'Europe', 'Italy': 'Europe', 'Kosovo': 'Europe',
    'Latvia': 'Europe', 'Liechtenstein': 'Europe', 'Lithuania': 'Europe', 'Luxembourg': 'Europe',
    'Malta': 'Europe', 'Moldova': 'Europe', 'Monaco': 'Europe', 'Montenegro': 'Europe',
    'Netherlands': 'Europe', 'North Macedonia': 'Europe', 'Norway': 'Europe', 'Poland': 'Europe',
    'Portugal': 'Europe', 'Romania': 'Europe', 'San Marino': 'Europe', 'Serbia': 'Europe',
    'Slovakia': 'Europe', 'Slovenia': 'Europe', 'Spain': 'Europe', 'Sweden': 'Europe',
    'Switzerland': 'Europe', 'Ukraine': 'Europe', 'UK': 'Europe', 'Vatican City': 'Europe',
    # Oceania
    'Australia': 'Oceania', 'New Zealand': 'Oceania'
}

train_set['Continent'] = train_set['Country'].map(country_to_continent)
test_set['Continent'] = test_set['Country'].map(country_to_continent)
train_set.drop(columns="Country", inplace=True)
test_set.drop(columns="Country", inplace=True)

# %%
features_cat.remove("Country")
features_cat.append("Continent")

# %%
fig, axes = plt.subplots(1, 2, figsize=(15, 5))

# Conteo de categorica
sns.countplot(train_set["Most_Used_Platform"], ax=axes[0])
axes[0].set_title("Most_Used_Platform")

# Categorica vs target
sns.countplot(x=train_set["Most_Used_Platform"], hue=train_set[target], ax=axes[1], dodge=False)
axes[1].set_title("Categórica vs target");

# %%
bt.plot_categorical_relationship_fin(train_set, "Continent",target, show_values= True, relative_freq= True)
features_important_cat.append("Continent") # relevante

# %%
# AGE
bins_dep = [-1, 18, 19, 20, 21, 22 , float("inf")]
labels_dep = ["hasta 18", 19, 20, 21, 22, "23 y mas"]
train_set["Age"] = pd.cut(train_set["Age"], bins=bins_dep, labels=labels_dep)
test_set["Age"] = pd.cut(test_set["Age"], bins=bins_dep, labels=labels_dep)

# %%
# GENDER - (Male = 0, Female =1, no hace flata transmorar ahora)
train_set["Gender"].value_counts()
train_set["Gender"].replace({
    "Male": 0, 
    "Female": 1
}, inplace=True)

test_set["Gender"].replace({
    "Male": 0, 
    "Female": 1
}, inplace=True)

# %%
# AFFECTS_ACADEMNIC_PERFORMANCE
train_set["Affects_Academic_Performance"].replace({
    "No": 0, 
    "Yes": 1
}, inplace=True)

test_set["Affects_Academic_Performance"].replace({
    "No": 0, 
    "Yes": 1
}, inplace=True)

# %%
# MOST_USED_PLATFORM 
mapped_platform= {
"Instagram": "Instagram",
"TikTok": "TikTok",
"Facebook": "Facebook",
"Whatsapp": "Others",
"Twitter": "Others",
"LinkedIn": "Others" ,
"WeChat": "Others",
"LINE": "Others", 
"KakaoTalk": "Others" ,
"YouTube": "Others" , 
"VKontakte": "Others", 
"Snapchat": "Others" }

train_set['Most_Used_Platform'] = train_set['Most_Used_Platform'].map(mapped_platform)
test_set['Most_Used_Platform'] = test_set['Most_Used_Platform'].map(mapped_platform)


# %%
# MENTAL_HEALTH_SCORE
bins_dep = [0, 4, 6,  float("inf")]
labels_dep = ["Poor", "Moderate", "Good"]
train_set["Mental_Health_Score"] = pd.cut(train_set["Mental_Health_Score"], bins=bins_dep, labels=labels_dep)
test_set["Mental_Health_Score"] = pd.cut(test_set["Mental_Health_Score"], bins=bins_dep, labels=labels_dep)
    


# %%
# TARGET - ADDCITED_SCORE (where 0 = "not addicted", 1 = "Moderate", 2 = "Addicted")
bins_dep = [0, 4, 7,  float("inf")]
labels_dep = [0, 1, 2]
train_set["Addicted_Score"] = pd.cut(train_set["Addicted_Score"], bins=bins_dep, labels=labels_dep)
test_set["Addicted_Score"] = pd.cut(test_set["Addicted_Score"], bins=bins_dep, labels=labels_dep)
    

# %%
# CONFLICTS_OVER_SOCIAL_MEDIA - esta ordenada, no haria falta transformarla, podriamos dejar numerica y quitarla del One-Hot-Encoding
#bins_dep = [0, 1, 3,  float("inf")]
#labels_dep = ["Not_Significant", "COUPLE", "SEVERAL"]
#train_set["Conflicts_Over_Social_Media"] = pd.cut(train_set["Conflicts_Over_Social_Media"], bins=bins_dep, labels=labels_dep)
#test_set["Conflicts_Over_Social_Media"] = pd.cut(test_set["Conflicts_Over_Social_Media"], bins=bins_dep, labels=labels_dep)
    

# %%
transformed_cat = ["Continent", "Age","Academic_Level", "Most_Used_Platform", "Mental_Health_Score", "Relationship_Status" ]
for col in transformed_cat:
    train_set= pd.get_dummies(train_set, columns=[col], drop_first=True, dtype=int)
    test_set= pd.get_dummies(test_set, columns=[col], drop_first=True, dtype=int)

# %%
train_set.columns.to_list()
features_cat = [col for col in train_set.columns.to_list() if col not in features_num]
features_cat.remove("Addicted_Score")

# %%
#verificamos que tenemos todas las mismas columnas en test_set que en train.
train_set.columns

# %%
train_set

# %%
len(train_set.columns.to_list())

# %%
len(test_set.columns.to_list())

# %% [markdown]
# ***6. Primer Baseline Model***

# %%

X_train = train_set.drop(target, axis = 1)
y_train = train_set[target]
X_test = test_set.drop(target, axis = 1)
y_test = test_set[target]

# %%
rfc = RandomForestClassifier( random_state=42,)
baseline = np.mean(cross_val_score(rfc,X_train,y_train, scoring = "balanced_accuracy", cv = 5))
print(f"Baseline: {baseline}%")

# %%
#Aplicamos un SMOTE para el balanceo del target, aseguremos asi el buen entrenamiento tambien de las clases minoritarias
sm = SMOTE(random_state=42)
X_smoted, y_smoted = sm.fit_resample(X_train, y_train)

rfc_smote = RandomForestClassifier(random_state=42, )
baseline_smoted = np.mean(cross_val_score(rfc_smote,X_smoted,y_smoted, scoring = "balanced_accuracy", cv = 5))
print(f"Baseline_smoted: {baseline_smoted}%")

# %%
rfc_smote.fit(X_smoted,y_smoted)
importances=rfc_smote.feature_importances_
indices = np.argsort(importances)

plt.figure(figsize=(6, 6))
plt.title('Feature Importances')
plt.barh(range(len(indices)), importances[indices], color='b', align='center')
plt.yticks(range(len(indices)), [X_train.columns[i] for i in indices])
plt.xlabel('Relative Importance')
plt.show()

# %%
feature_names = X_smoted.columns
feat_imp = pd.DataFrame({
    'feature': feature_names,
    'importance': importances
}).sort_values(by='importance', ascending=False)
top6_random_forest = feat_imp.head(6)['feature'].tolist()
top6_random_forest

# %%
from sklearn.feature_selection import mutual_info_classif
X_smoted_mut = X_smoted[features_cat]
selector = SelectKBest(mutual_info_classif, k=10)
x_kbest = selector.fit_transform(X_smoted_mut, y_smoted)
mutual_info = pd.DataFrame(x_kbest, columns = selector.get_feature_names_out())
select_mutual_info_features= mutual_info.columns
select_mutual_info_features

# %%
# con los one hot encoding, se nos ha generado muchas nuevas features, vamos a intentar reducir para ver si mejoramos el modelo base

# %% [markdown]
# *** 7. Seleccion de Features***

# %%
print(f"{features_important_cat}")
print(f"{features_important_num}")
print(f"{less_important_features}")

# %%
# Teniamos una seleccion visual, pero tras las transformaciones hay que actualizar la lista
less_important_features_enc= ['Age_19', 'Age_20', 'Age_21', 'Age_22',
       'Age_23 y mas','Sleep_Hours_Per_Night' ]

# %%
features_visual_final = [col for col in train_set.columns.to_list() if col not in less_important_features_enc]
features_visual_final.remove(target)
features_visual_final

# %%
# Modelo con seleccion visual de features

X_smoted_visual = X_smoted[features_visual_final]

#Random Forest Classifier
rfc_vis_smoted = RandomForestClassifier(n_estimators=100, random_state=42, max_depth=5)

visual_score = np.mean(cross_val_score(rfc_vis_smoted, X_smoted_visual, y_smoted, cv = 5, scoring= "balanced_accuracy"))
num_feats_visual = len(features_visual_final)
num_feats_baseline = len(X_train.columns)
print(f"Visual: {visual_score*100.0}%/{len(features_visual_final)} feats. vs Baseline_sm: {baseline_smoted*100.0}%/{num_feats_baseline} feats.")

# %%
# ANOVA (no es correcto, es para numericas solo)
#from sklearn.feature_selection import SelectKBest
#names= X_smoted.columns
#sel = SelectKBest(k=6)
#X_new = sel.fit_transform(X_smoted, y_smoted)

#selectKbest = pd.DataFrame({'column': names, 'score': sel.scores_}).sort_values('score', ascending=False)
#features_anova = selectKbest['column'].head(6).tolist() 
#features_anova

# %%
# Transformar el dataset a solo las 5 mejores características
#X_train_anova = select_feature.transform(X_train)


#Random Forest Classifier
#rfc_2 = RandomForestClassifier(n_estimators=100, random_state=42, max_depth=5)

#anova_score = np.mean(cross_val_score(rfc_2, X_train[features_anova], y_train, cv = 5, scoring= "balanced_accuracy"))

#print(f"ANOVA: {anova_score*100.0}%/{k_anova} feats. vs Baseline: {baseline*100.0}%/{num_feats_baseline} feats.")

# %%
# RECURSIVE FEATURE ELIMINATION (RFE)

rfc_3 = RandomForestClassifier(n_estimators=100, random_state=42, max_depth=5)

#Recursive Feature Elimination y entrenar el modelo
features_rfe = 10
rfe = RFE(estimator=rfc_3, n_features_to_select= features_rfe, step=1)
rfe = rfe.fit(X_smoted, y_smoted)
X_smoted_rfe = rfe.transform(X_smoted)

rfe_score = np.mean(cross_val_score(rfc_3, X_smoted_rfe, y_smoted, cv = 5, scoring= "balanced_accuracy"))

print(f"RFE: {rfe_score*100.0}%/{features_rfe} feats. vs Baseline: {baseline*100.0}%/{num_feats_baseline} feats.")

# %%
features_rfe = rfe.get_feature_names_out()
features_rfe

# %%
from sklearn.feature_selection import RFECV

rfc_4 = RandomForestClassifier(n_estimators=100, random_state=42, max_depth=5) 
rfecv = RFECV(estimator=rfc_4, step=1, cv=5,scoring='balanced_accuracy')
rfecv = rfecv.fit(X_smoted, y_smoted)

features_RFECV= rfecv.get_feature_names_out()
print('Optimal number of features :', rfecv.n_features_)
#print('Best features :', list(X_smoted.columns[rfecv.support_]))
#print("Best features (alternative:", rfecv.get_feature_names_out())
print('Accuracy feat. reduction 4:', np.mean(cross_val_score(rfc_4, X_smoted[rfecv.get_feature_names_out()],y_smoted, cv = 5, scoring = "balanced_accuracy")))

# %%
# vamos a intentar la PCA aunque Requiere escalado previo (StandardScaler) y perdamos explicabilidad pq, los componentes ya no tienen un significado directo

#scaler = StandardScaler()
#train_scaled = scaler.fit_transform(X_smoted)
#test_scaled = scaler.transmord(x_test)



# %%
X_train.hist(figsize=(12,12));

# %%
#pca = PCA(n_components=0.98)  # mantener 95% de varianza
#X_pca = pca.fit_transform(X_scaled)

# %%
#pca.n_components_

# %%
#pca.explained_variance_ratio_.cumsum()

# %%
#rfc_5 = RandomForestClassifier(n_estimators=100, random_state=42, max_depth=5) 

#pca_score = np.mean(cross_val_score(rfc_5, X_pca, y_train, cv = 5, scoring= "balanced_accuracy"))
#pca_score

# %%
# Instanciamos modelos
log_reg_pipe = make_pipeline(
    StandardScaler(),
    LogisticRegression(class_weight="balanced", random_state=42))
knn_pipe = make_pipeline(
    StandardScaler(),
    KNeighborsClassifier(n_neighbors=5, weights='distance'))
dtc= DecisionTreeClassifier(class_weight='balanced', random_state=42)
gbc = GradientBoostingClassifier( random_state=42)
xgb = XGBClassifier(objective='multi:softprob',    random_state=42)
lgb = LGBMClassifier(class_weight='balanced', random_state=42, verbose = -1)
cb = CatBoostClassifier( auto_class_weights='Balanced',random_state=42,verbose=0  )


# %%
listas_features = {
    "top6_random_forest": top6_random_forest,
    "select_mutual_info_features": select_mutual_info_features,
    "features_rfe": features_rfe,
    "features_RFECV": features_RFECV
}

resultado = []
for nombre_lista, lista in listas_features.items():
    for nombre, modelo in zip(["Logistic Regresion","KNN", "Decision tree Classifier", "Gardient Boosting", "XGB Classifier", "Light BGM", "CatBoost"],
                              [log_reg_pipe, knn_pipe, dtc, gbc, xgb, lgb,cb]):
        score= np.mean(cross_val_score(modelo, X_smoted[lista], y_smoted, cv = 5, scoring = "balanced_accuracy"))
        resultado.append({
            "feature_list": nombre_lista,
            "list_len": len(lista),
            "model": nombre,
            "balanced_accuracy": score*100
        })
df_resultados = pd.DataFrame(resultado)
df_resultados.sort_values(by='balanced_accuracy', ascending=False).reset_index(drop=True)   

# %%
# por el tiempo de ejecucion de y los resultdos obtenido, nos quedaremos con el Desicion tree, ya que tiene muy buena metrica. 
# ahora vamos a pasar a optimizarlo.

# LINEA 5 del df_resultados : decision tree classifier + features_RFECV

# %%

params = {
    'max_depth': [3, 5, 10, None],
    'min_samples_split': [2, 5, 10],
    'min_samples_leaf': [1, 2, 4],
    'max_features': ['sqrt', 'log2', None],
    'criterion': ['gini', 'entropy'],
}

dt = DecisionTreeClassifier(random_state=42, class_weight='balanced')

grid_search = GridSearchCV(
        dt, 
        param_grid=params, 
        scoring='balanced_accuracy', 
        cv=5, 
        n_jobs=-1
        )
grid_search.fit(X_smoted[features_RFECV], y_smoted)


# %%


best_model = grid_search.best_estimator_  # el modelo entrenado
y_pred = best_model.predict(X_test[features_RFECV])
print("Mejores hiperparámetros:", grid_search.best_params_)
print("Mejor score:", grid_search.best_score_)
y_pred

# %%
from sklearn.metrics import balanced_accuracy_score
test_balanced_acc = balanced_accuracy_score(y_test, y_pred)
print(f"Balanced Accuracy (Test): {test_balanced_acc*100:.2f}%")

# %%
# EVALUACION DEL MODELO

matriz_confusion = confusion_matrix(y_test, y_pred)
plt.figure(figsize=(5,4))
sns.heatmap(matriz_confusion, annot=True, fmt='d', cmap='Blues')
plt.xlabel("Predicted")
plt.ylabel("Actual")
plt.title("Confusion Matrix")
plt.show()

# %%
# sobre 39 predecicdo como addicted, solo 1 lo esta de manera moderada
# sobre 27 predecidos como no addicted, 10 son moderados
# sobre 75 predecidos como moderados, solo1 no esta adicted. 
# el modelo predice mejor los adicted, lo que es lo que queremos como negoscio porque es alli que queremos poder acutar y preever medidas precvnetivas. 
# por lo tanto tb es necesario saber las features mas improtantes para ello. 



# %%
features_RFECV

# %%
# Guardar el modelo
import pickle

with open('adiccion_redes_sociales', "wb") as archivo_salida:
    pickle.dump(grid_search.best_estimator_, archivo_salida)




